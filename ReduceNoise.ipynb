{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------------\n",
    "# 基本配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()\n",
    "\n",
    "# -----------------------------------\n",
    "# 数据预处理\n",
    "dataset = datasets.MNIST('data/',download=True)\n",
    "data = dataset.data.reshape(-1, 1, 28, 28).float().to(device)\n",
    "\n",
    "data_x = (data + 80 * torch.rand(60000, 1, 28, 28).to(device)).clamp(0, 255)/ 255.\n",
    "# 添加噪声并归一化，数据x是添加噪声后的图\n",
    "data_y = data / 255.\n",
    "# 归一化，数据y是原图\n",
    "# plt.imshow(data_y[0].cpu().squeeze())\n",
    "# plt.show()\n",
    "# plt.imshow(data_x[0].cpu().squeeze())\n",
    "# plt.show()\n",
    "\n",
    "# 分割训练和测试集\n",
    "train_x, train_y = data_x[:50000], data_y[:50000]\n",
    "test_x, test_y = data_x[50000:], data_y[50000:]\n",
    "\n",
    "# -----------------------------------\n",
    "# 定义网络模型\n",
    "class net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.layer1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        # (-1, 1, 28, 28) -> (-1, 32, 28, 28)\n",
    "        self.layer2 = nn.MaxPool2d(2, stride=2)\n",
    "        # (-1, 32, 28, 28) -> (-1, 32, 14, 14)\n",
    "        self.layer3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.layer4 = nn.MaxPool2d(2, stride=2)\n",
    "        # (-1, 32, 14, 14) -> (-1, 32, 7, 7)\n",
    "        self.layer5 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.layer6 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        # (-1, 32, 7, 7) -> (-1, 32, 14, 14)\n",
    "        self.layer7 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.layer8 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        # (-1, 32, 14, 14) -> (-1, 32, 28, 28)\n",
    "        self.layer9 = nn.Conv2d(32, 1, kernel_size=3, stride=1, padding=1)\n",
    "        # (-1, 32, 28, 28) -> (-1, 1, 28, 28)\n",
    "    def forward(self,x):\n",
    "        x = self.sigmoid(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        x = self.sigmoid(self.layer3(x))\n",
    "        x = self.layer4(x)\n",
    "        x = self.sigmoid(self.layer5(x))\n",
    "        x = self.layer6(x)\n",
    "        x = self.sigmoid(self.layer7(x))\n",
    "        x = self.layer8(x)\n",
    "        x = self.sigmoid(self.layer9(x))\n",
    "        return x\n",
    "\n",
    "# -----------------------------------\n",
    "# 定义网络、损失函数和优化器\n",
    "model = net().to(device)\n",
    "loss_fun = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# -----------------------------------\n",
    "# 训练模型\n",
    "# model.load_state_dict(torch.load(\"autodecode.mdl\"))\n",
    "# # 载入已保存模型\n",
    "\n",
    "batch_size = 1000\n",
    "# 开始训练\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    for batch in range(0, 50000 - batch_size, batch_size):\n",
    "        output = model(train_x[batch: batch+batch_size])\n",
    "        loss = loss_fun(train_y[batch: batch+batch_size], output)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    test_output = model(test_x)\n",
    "    loss_test = loss_fun(test_y, test_output)\n",
    "    print('Epoch: {}, Loss: {}, test_loss: {}'.format(epoch, loss.data, loss_test.data))\n",
    "    torch.save(model.state_dict(), \"autodecode.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# 测试模型\n",
    "model.eval()\n",
    "test_output = model(test_x[:1000]).cpu()\n",
    "train_output = model(train_x[:1000]).cpu()\n",
    "\n",
    "# -----------------------------------\n",
    "# 显示降噪后的效果对比\n",
    "n = 10\n",
    "plt.figure(figsize=(10, 50))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(n, 3, i*3 + 1)\n",
    "    plt.imshow((test_x[i*3 + 1].cpu().squeeze().detach().numpy() * 255.).astype(np.int))\n",
    "    ax = plt.subplot(n, 3, i*3 + 2)\n",
    "    plt.imshow((test_output[i*3 + 1].cpu().squeeze().detach().numpy() * 255.).astype(np.int))\n",
    "    ax = plt.subplot(n, 3, i*3 + 3)\n",
    "    plt.imshow((test_y[i*3 + 1].cpu().squeeze().detach().numpy() * 255.).astype(np.int))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] 目录名称无效。: 'D:\\\\1mylearningdata\\\\1mphil\\\\Competition\\\\NCCCU2022\\\\1my\\\\train\\\\data\\\\3\\\\b.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32md:\\1mylearningdata\\1mphil\\Competition\\NCCCU2022\\1my\\ReduceNoise.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/1mylearningdata/1mphil/Competition/NCCCU2022/1my/ReduceNoise.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtransforms\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/1mylearningdata/1mphil/Competition/NCCCU2022/1my/ReduceNoise.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# img=cv2.imread(r\"D:\\1mylearningdata\\1mphil\\Competition\\NCCCU2022\\1my\\train\\data\\3\\b.jpg\")\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/1mylearningdata/1mphil/Competition/NCCCU2022/1my/ReduceNoise.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# img = np.array([img])  #把图像数据放到python中括号中,并用numpy转换为np数据类型\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/1mylearningdata/1mphil/Competition/NCCCU2022/1my/ReduceNoise.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# img = torch.from_numpy(img).float()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/1mylearningdata/1mphil/Competition/NCCCU2022/1my/ReduceNoise.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# img=transforms.ToTensor()(img)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/1mylearningdata/1mphil/Competition/NCCCU2022/1my/ReduceNoise.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# img=img.convert('L')\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/1mylearningdata/1mphil/Competition/NCCCU2022/1my/ReduceNoise.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# img=transforms.Lambda(lambda x: x.repeat(1,1,1))(img)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/1mylearningdata/1mphil/Competition/NCCCU2022/1my/ReduceNoise.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m img\u001b[39m=\u001b[39mdatasets\u001b[39m.\u001b[39;49mImageFolder(\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mD:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m1mylearningdata\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m1mphil\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mCompetition\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mNCCCU2022\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m1my\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m3\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mb.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1mylearningdata/1mphil/Competition/NCCCU2022/1my/ReduceNoise.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m img2 \u001b[39m=\u001b[39m model(img)\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1mylearningdata/1mphil/Competition/NCCCU2022/1my/ReduceNoise.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m\"\u001b[39m, img)\n",
      "File \u001b[1;32md:\\Softwares\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\folder.py:310\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    303\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    304\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m ):\n\u001b[1;32m--> 310\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    311\u001b[0m         root,\n\u001b[0;32m    312\u001b[0m         loader,\n\u001b[0;32m    313\u001b[0m         IMG_EXTENSIONS \u001b[39mif\u001b[39;49;00m is_valid_file \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    314\u001b[0m         transform\u001b[39m=\u001b[39;49mtransform,\n\u001b[0;32m    315\u001b[0m         target_transform\u001b[39m=\u001b[39;49mtarget_transform,\n\u001b[0;32m    316\u001b[0m         is_valid_file\u001b[39m=\u001b[39;49mis_valid_file,\n\u001b[0;32m    317\u001b[0m     )\n\u001b[0;32m    318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples\n",
      "File \u001b[1;32md:\\Softwares\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\folder.py:145\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    136\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    137\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    143\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, transform\u001b[39m=\u001b[39mtransform, target_transform\u001b[39m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 145\u001b[0m     classes, class_to_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_classes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[0;32m    146\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39m=\u001b[39m loader\n",
      "File \u001b[1;32md:\\Softwares\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\folder.py:219\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(\u001b[39mself\u001b[39m, directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[0;32m    193\u001b[0m     \u001b[39m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[39m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m     \u001b[39mreturn\u001b[39;00m find_classes(directory)\n",
      "File \u001b[1;32md:\\Softwares\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\folder.py:41\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[0;32m     37\u001b[0m     \u001b[39m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[39m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     classes \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(entry\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mscandir(directory) \u001b[39mif\u001b[39;00m entry\u001b[39m.\u001b[39mis_dir())\n\u001b[0;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[0;32m     43\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find any class folder in \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] 目录名称无效。: 'D:\\\\1mylearningdata\\\\1mphil\\\\Competition\\\\NCCCU2022\\\\1my\\\\train\\\\data\\\\3\\\\b.jpg'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "# img=cv2.imread(r\"D:\\1mylearningdata\\1mphil\\Competition\\NCCCU2022\\1my\\train\\data\\3\\b.jpg\")\n",
    "# img = np.array([img])  #把图像数据放到python中括号中,并用numpy转换为np数据类型\n",
    "# img = torch.from_numpy(img).float()\n",
    "# img=transforms.ToTensor()(img)\n",
    "# img=img.convert('L')\n",
    "# img=transforms.Lambda(lambda x: x.repeat(1,1,1))(img)\n",
    "\n",
    "img=datasets.ImageFolder(r\"D:\\1mylearningdata\\1mphil\\Competition\\NCCCU2022\\1my\\train\\data\\3\\b.jpg\")\n",
    "\n",
    "img2 = model(img).cpu()\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"img2\", img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc40295abfe64802fc0a773300b50725a51b24d09df8dee4b845a03d985ddb9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
